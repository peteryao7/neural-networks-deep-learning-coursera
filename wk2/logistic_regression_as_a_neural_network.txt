Binary Classification

How to process a training set with m training examples without a for loop.

Input: some image
Output: a label (0/1)

Ex: Cat photos
    - input: an image represented by 3 matrices of red/green/blue pixel values
    - output: 1 (cat) vs. 0 (not cat)

    - unrolling the matrices into a feature vector x
        - define a vector x = [ all red values   ]
                              [ all green values ]
                              [ all blue values  ]
        - now have a vector (a * b * 3) x 1 vector

Notation
    - (x, y) represents a single training pair, where x ∈ R^(n_x) and y ∈ {0,1}
    - m represents the number of training examples in your training set
    - ((x^(1), y^(1)), (x^(2), y^(2)), ..., (x^(m), y^(m)) is the training set
    - capital X is the matrix with stacked training inputs
        X = [  |     |   ...   |  ]
            [x^(1) x^(2) ... x^(m)]
            [  |     |   ...   |  ]

                X ∈ R^(n_x x m)
    
        Y = [y^(1) y^(2) ... y^(m)]

==================================================

Logistic Regression

Given an input feature vector x (image), want yhat = P(y=1 | x).

Parameters of logistic regression:
    w ∈ R^(n_x)
    b ∈ R

Output: yhat = sigmoid(w^Tx + b), where w^Tx + b = z

Sigmoid function
    σ(z) = 1 / (1 + e^(-z))
    - If z large, σ(z) is close to 1
    - If z a large negative number, σ(z) is close to 0

==================================================

Logistic Regression Cost Function

Given {(x^(1), y^(1)), ... (x^(m), y^(m))}, want yhat^(i) to be close to y^(i).

Loss (error) function:
    - measures how well your algorithm is doing

    - one sample function: ℒ(yhat, y) = 1/2 * (yhat-y)^2
        - squared error
        - not that great, the optimization problem becomes non-convex and leads to multiple local optima
        - so gradient descent may not find the global optimum

    ℒ(yhat, y) = -(y*log(yhat) + (1-y) * log(1-yhat))
        - if y=1, ℒ(yhat, y) = -log(yhat), meaning you want log(yhat) to be large, and yhat to be large
        - if y=0, ℒ(yhat, y) = -log(1-yhat), meaning you want log(1-yhat) to be large, and yhat to be small

Cost function: J(w,b) = (1/m) * sum(i=1,m) ℒ(yhat^(i), y^(i))
                      = (-1/m) * sum(i=1,m) [y^(i) * log(yhat^(i)) + (1-y^(i)) * log(1-yhat^(i))]

The loss function computes the error for one training example.
The cost function is the avg of the loss functions of the whole training set.

==================================================

Gradient Descent

Recap
    yhat = sigmoid(w^Tx + b), where w^Tx + b = z
    J(w,b) = (1/m) * sum(i=1,m) ℒ(yhat^(i), y^(i))
           = (-1/m) * sum(i=1,m) [y^(i) * log(yhat^(i)) + (1-y^(i)) * log(1-yhat^(i))]

